{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths of the folders containing the images\n",
    "clean_covid_folder = 'dataset/clean_images/COVID'\n",
    "clean_lung_opacity_folder = 'dataset/clean_images/Lung_Opacity'\n",
    "clean_normal_folder = 'dataset/clean_images/Normal'\n",
    "clean_viral_pneumonia_folder = 'dataset/clean_images/Viral_Pneumonia'\n",
    "clean_folders = [clean_covid_folder, clean_lung_opacity_folder, clean_normal_folder, clean_viral_pneumonia_folder]\n",
    "\n",
    "# Resized image directories\n",
    "resized_covid_folder = 'dataset/resized_images/COVID'\n",
    "resized_lung_opacity_folder = 'dataset/resized_images/Lung_Opacity'\n",
    "resized_normal_folder = 'dataset/resized_images/Normal'\n",
    "resized_viral_pneumonia_folder = 'dataset/resized_images/Viral_Pneumonia'\n",
    "resized_folders = [resized_covid_folder, resized_lung_opacity_folder, resized_normal_folder, resized_viral_pneumonia_folder]\n",
    "\n",
    "# Directories to save the standardized images\n",
    "standardized_covid_folder = 'dataset/standardized_images/COVID'\n",
    "standardized_lung_opacity_folder = 'dataset/standardized_images/Lung_Opacity'\n",
    "standardized_normal_folder = 'dataset/standardized_images/Normal'\n",
    "standardized_viral_pneumonia_folder = 'dataset/standardized_images/Viral_Pneumonia'\n",
    "standardized_folders = [standardized_covid_folder, standardized_lung_opacity_folder, standardized_normal_folder, standardized_viral_pneumonia_folder]\n",
    "\n",
    "# Directories to save the featured images\n",
    "featured_covid_folder = 'dataset/featured_images/COVID'\n",
    "featured_lung_opacity_folder = 'dataset/featured_images/Lung_Opacity'\n",
    "featured_normal_folder = 'dataset/featured_images/Normal'\n",
    "featured_viral_pneumonia_folder = 'dataset/featured_images/Viral_Pneumonia'\n",
    "featured_folders = [featured_covid_folder, featured_lung_opacity_folder, featured_normal_folder, featured_viral_pneumonia_folder]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images of the folder with its label\n",
    "def load_data(image_folder, label):\n",
    "    data = []\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.endswith('.png'):\n",
    "            img_path = os.path.join(image_folder, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            tensor = tf.convert_to_tensor(img)\n",
    "            data.append([tensor, label])\n",
    "    return data\n",
    "\n",
    "# Shows information of folders and the images\n",
    "def info(folders, img):\n",
    "    print(\"Image dimensions:\", img.shape)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    counts = [len(os.listdir(folder)) for folder in folders]\n",
    "    class_labels = ['COVID', 'Lung Opacity', 'Normal', 'Viral Pneumonia']\n",
    "    data = {'Class': class_labels, 'Count': counts}\n",
    "    df = pd.DataFrame(data).style.hide()\n",
    "    \n",
    "    print(\"Number of images per class\")\n",
    "    return df\n",
    "    \n",
    "# Create directories if it doesn't exist\n",
    "def create_directories(folders):\n",
    "    for folder in folders:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        \n",
    "        \n",
    "# Convert to string time\n",
    "def get_str_time(time):\n",
    "    hours = int(time // 3600)\n",
    "    minutes = int((time % 3600) // 60)\n",
    "    seconds = int(time % 60)\n",
    "    if hours == 0:\n",
    "        if minutes == 0:\n",
    "            return f'{seconds}s'\n",
    "        return f'{minutes}m {seconds}s'\n",
    "    return f'{hours}h {minutes}m {seconds}s'\n",
    "\n",
    "# Calculate the metrics using sklearn.metrics\n",
    "def get_metrics(model, X_test, y_test, time):\n",
    "    # Get the model predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "    # Get metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    precision = precision_score(y_test, y_pred_classes, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred_classes, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_classes, average='weighted', zero_division=0)\n",
    "    # Output\n",
    "    results = [accuracy, precision, recall, f1, time]\n",
    "    df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Recall', 'Precision', 'F1Score', 'Training time'],\n",
    "    'Scores': results\n",
    "    }).style.hide().set_properties(**{'text-align': 'left'})\n",
    "\n",
    "    return results, df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show information\n",
    "image = cv2.imread(clean_covid_folder+'/COVID-1.png', cv2.IMREAD_GRAYSCALE)\n",
    "df = info(folders=clean_folders, img=image)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. FEATURE ENGINEERING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se toma una cantidad especifica de cada conjunto para que haya una similitud entre todos los conjuntos y se redimensionan a 128x128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "create_directories(resized_folders)\n",
    "\n",
    "# Function to resize images and save them in the new directories\n",
    "def resize_and_save_images(image_folder, resized_folder, samples):\n",
    "    image_files = os.listdir(image_folder)\n",
    "    image_files = image_files[:samples]  # Select the specified number of samples\n",
    "    for file_name in image_files:\n",
    "        img_path = os.path.join(image_folder, file_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        resized_img = cv2.resize(img, (128, 128))  # Resize the image\n",
    "        new_file_name = os.path.splitext(file_name)[0] + '_resized.png'  # New file name\n",
    "        cv2.imwrite(os.path.join(resized_folder, new_file_name), resized_img)\n",
    "\n",
    "# Resize images and save images\n",
    "num_samples = [3616, 3700, 3700, 1345]\n",
    "[resize_and_save_images(clean_folder, resized_folder, samples) for clean_folder, resized_folder, samples in zip(clean_folders, resized_folders, num_samples)]\n",
    "print(\"STANDARDIZED IMAGES SAVED IN THE NEW DIRECTORIES.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estandarizan las imágenes después del redimensionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show information\n",
    "image = cv2.imread(resized_covid_folder+'/COVID-1_resized.png', cv2.IMREAD_GRAYSCALE)\n",
    "df = info(folders=resized_folders, img=image)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "create_directories(standardized_folders)\n",
    "\n",
    "# Function to standardize and save images to new directories\n",
    "def standardize_and_save_images(resized_folder, standardized_folder):\n",
    "    for filename in os.listdir(resized_folder):\n",
    "        if filename.endswith('.png'):\n",
    "            image_path = os.path.join(resized_folder, filename)  # Path to the current image\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load the image in grayscale\n",
    "            image_float = image.astype(\"float32\")  # Convert the image to a float32 NumPy array\n",
    "            mean, std_dev = cv2.meanStdDev(image_float)  # Calculate mean and standard deviation\n",
    "            standardized_mean = 127\n",
    "            standardized_std_dev = 63\n",
    "            standardized_image = (image_float - mean) / std_dev * standardized_std_dev + standardized_mean\n",
    "            standardized_image_uint8 = standardized_image.astype(\"uint8\")  # Convert image to uint8\n",
    "            new_filename = os.path.splitext(filename)[0] + '_standardized.png'  # New file name\n",
    "            cv2.imwrite(os.path.join(standardized_folder, new_filename), standardized_image_uint8)  # Save the standardized image\n",
    "\n",
    "# Standardize and save images\n",
    "[standardize_and_save_images(resized_folder, standardized_folder) for resized_folder, standardized_folder in zip(resized_folders, standardized_folders)]\n",
    "print(\"STANDARDIZED IMAGES SAVED IN THE NEW DIRECTORIES.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show information\n",
    "image = cv2.imread(standardized_covid_folder+'/COVID-1_resized_standardized.png', cv2.IMREAD_GRAYSCALE)\n",
    "df = info(folders=standardized_folders, img=image)\n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. FEATURE EXTRACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "\n",
    "# Create directories if they don't exist\n",
    "create_directories(featured_folders)\n",
    "\n",
    "# Aplica el extractor de Histogramas de Color\n",
    "def color_histograms(image):\n",
    "    hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "    n = sum(hist.flatten())\n",
    "    hist_normalized = hist.flatten() / n\n",
    "    return hist_normalized\n",
    "\n",
    "# Aplica Local Binary Patterns\n",
    "radius = 1 # Radius of the circle used to calculate the patterns\n",
    "points = 8 * radius # Number of sampling points on the circle\n",
    "def local_binary_patterns(image):\n",
    "    lbp = feature.local_binary_pattern(image, points, radius, method='uniform')\n",
    "    # lbp_normalized = np.uint8((lbp / np.max(lbp)) * 255)\n",
    "    lbp_normalized = cv2.normalize(lbp, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    return lbp_normalized\n",
    "\n",
    "# Function to standardize and save images to new directories\n",
    "def apply_feature_extractor(standardized_folder, featured_folder, filter):\n",
    "    for filename in os.listdir(standardized_folder):\n",
    "        image_path = os.path.join(standardized_folder, filename)   # Path to the current image        \n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load the image in grayscale\n",
    "        \n",
    "        # Applies the corresponding extractor according to the type of filter\n",
    "        if   filter.lower() == \"histo\" : featured_image = color_histograms(image)\n",
    "        elif filter.lower() == \"lbp\"   : featured_image = local_binary_patterns(image)\n",
    "        else:\n",
    "            print(\"Tipo de filtro no válido. Debe ser 'Histo' o 'LBP'.\")\n",
    "            continue\n",
    "    \n",
    "        # Save the result as an image in the output directory\n",
    "        new_filename = os.path.splitext(filename)[0].replace(\"_resized_standardized\", \"\") + '_featured.png'  # New file name\n",
    "        cv2.imwrite(os.path.join(featured_folder, new_filename), featured_image) # Save the image\n",
    "\n",
    "# Standardize and save images\n",
    "feature_extractor = 'LBP'\n",
    "[apply_feature_extractor(standardized_folder, featured_folder, filter=feature_extractor) for standardized_folder, featured_folder in zip(standardized_folders, featured_folders)]\n",
    "print(\"FEATURED IMAGES SAVED IN THE NEW DIRECTORIES.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show information\n",
    "image = cv2.imread(featured_covid_folder+'/COVID-1_featured.png', cv2.IMREAD_GRAYSCALE)\n",
    "df = info(folders=featured_folders, img=image)\n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TRAINING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data of 'X' and 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lung images\n",
    "# covid_data = load_data(standardized_covid_folder, 0)\n",
    "# lung_opacity_data = load_data(standardized_lung_opacity_folder, 1)\n",
    "# normal_data = load_data(standardized_normal_folder, 2)\n",
    "# viral_pneumonia_data = load_data(standardized_viral_pneumonia_folder, 3)\n",
    "covid_data = load_data(featured_covid_folder, 0)\n",
    "lung_opacity_data = load_data(featured_lung_opacity_folder, 1)\n",
    "normal_data = load_data(featured_normal_folder, 2)\n",
    "viral_pneumonia_data = load_data(featured_viral_pneumonia_folder, 3)\n",
    "data = covid_data + lung_opacity_data + normal_data + viral_pneumonia_data\n",
    "\n",
    "# Split the list into two separate lists: one for the data and one for the labels\n",
    "tensor_list  = [item[0] for item in data]\n",
    "label_list = [item[1] for item in data]\n",
    "\n",
    "# Combine the data and labels into an unordered list of tuples\n",
    "combined_list = list(zip(tensor_list, label_list))\n",
    "random.shuffle(combined_list)\n",
    "\n",
    "# Separate the combined list into two separate lists again: one for the data and one for the labels\n",
    "X, y = zip(*combined_list)\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], -1))\n",
    "y_train_categorical = to_categorical(y_train, num_classes=4)\n",
    "y_test_categorical = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "# Check the dimensions of the training and test sets\n",
    "pd.DataFrame({\n",
    "    'Variable': ['X train', 'y train',  'X test', 'y test'],\n",
    "    'Dimensions': [X_train_reshaped.shape, y_train_categorical.shape, X_test_reshaped.shape, y_test_categorical.shape],\n",
    "}).style.hide().set_properties(**{'text-align': 'left'})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MLP model\n",
    "model1 = Sequential()\n",
    "model1.add(Flatten(input_shape=(X_train_reshaped.shape[1],)))\n",
    "model1.add(Dense(200, activation='relu'))\n",
    "model1.add(Dense(100, activation='relu'))\n",
    "model1.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'Recall', 'Precision'])\n",
    "\n",
    "# Train model\n",
    "start = time.time()\n",
    "model1.fit(X_train_reshaped, y_train_categorical, batch_size=100, epochs=10, verbose=2)\n",
    "train_time = get_str_time(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "results1, df1 = get_metrics(model=model1, X_test=X_test_reshaped, y_test=y_test, time=train_time)\n",
    "df1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MLP model\n",
    "model2 = Sequential()\n",
    "model2.add(Flatten(input_shape=(X_train_reshaped.shape[1],)))\n",
    "model2.add(Dense(100, activation='sigmoid'))\n",
    "model2.add(Dense(80, activation='sigmoid'))\n",
    "model2.add(Dense(60, activation='sigmoid'))\n",
    "model2.add(Dense(40, activation='sigmoid'))\n",
    "model2.add(Dense(20, activation='sigmoid'))\n",
    "model2.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'Recall', 'Precision'])\n",
    "\n",
    "# Train model\n",
    "start = time.time()\n",
    "model2.fit(X_train_reshaped, y_train_categorical, epochs=100, verbose=2)\n",
    "train_time = get_str_time(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "results2, df2 = get_metrics(model=model2, X_test=X_test_reshaped, y_test=y_test, time=train_time)\n",
    "df2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MLP model\n",
    "model3 = Sequential()\n",
    "model3.add(Flatten(input_shape=(X_train_reshaped.shape[1],)))\n",
    "model3.add(Dense(1000, activation='sigmoid'))\n",
    "model3.add(Dense(200, activation='sigmoid'))\n",
    "model3.add(Dense(10, activation='relu'))\n",
    "model3.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'Recall', 'Precision'])\n",
    "\n",
    "# Train model\n",
    "start = time.time()\n",
    "model3.fit(X_train_reshaped, y_train_categorical, epochs=100, verbose=2)\n",
    "train_time = get_str_time(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "results3, df3 = get_metrics(model=model3, X_test=X_test_reshaped, y_test=y_test, time=train_time)\n",
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Recall', 'Precision', 'Training time'],\n",
    "    'Arch 1': results1,\n",
    "    'Arch 2': results2,\n",
    "    'Arch 3': results3,\n",
    "}).style.hide().set_properties(**{'text-align': 'left'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
