{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature engineering\n",
    "## 2. Proponer las 3 arquitecturas\n",
    "## 3. Seleccionar la mejor\n",
    "## 4. Crear version con feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medicion de metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(y_pred, y_prueba):\n",
    "    recall = recall_score(y_prueba, y_pred, average='macro')\n",
    "    return recall\n",
    "\n",
    "def calculate_accuracy(y_pred, y_prueba):\n",
    "    correct = np.sum(np.array(y_pred) == np.array(y_prueba))\n",
    "    total = len(y_prueba)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "def calculate_precision(y_pred, y_prueba):\n",
    "    precision = precision_score(y_prueba, y_pred, average='macro', zero_division=1)\n",
    "    return precision\n",
    "\n",
    "def calculate_f1_score(y_pred, y_prueba):\n",
    "    f1 = f1_score(y_prueba, y_pred, average='macro')\n",
    "    return f1\n",
    "\n",
    "def calculate_metrics(y_pred, y_prueba, start_time, end_time):\n",
    "    recall = calculate_recall(y_pred, y_prueba)\n",
    "    accuracy = calculate_accuracy(y_pred, y_prueba)\n",
    "    precision = calculate_precision(y_pred, y_prueba)\n",
    "    f1 = calculate_f1_score(y_pred, y_prueba)\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    print(pd.DataFrame({\n",
    "    'Metric': ['Recall', 'Precision', 'Accuracy', 'F1', 'Training Time'],\n",
    "    'Score': [recall, accuracy, precision, f1, training_time]\n",
    "    }))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga del set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Rutas de las carpetas que contienen las imágenes\n",
    "covid_folder = 'dataset/images/COVID'\n",
    "lung_opacity_folder = 'dataset/images/Lung_Opacity'\n",
    "normal_folder = 'dataset/images/Normal'\n",
    "viral_pneumonia_folder = 'dataset/images/Viral Pneumonia'\n",
    "\n",
    "# Lista para almacenar las imágenes y las etiquetas correspondientes\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Cargar imágenes de pulmones con COVID\n",
    "for filename in os.listdir(covid_folder):\n",
    "    if filename.endswith('.png'):\n",
    "        img = cv2.imread(os.path.join(covid_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        X.append(img)\n",
    "        y.append(0)  # Etiqueta 0 para COVID\n",
    "\n",
    "# Cargar imágenes de pulmones con opacidad\n",
    "for filename in os.listdir(lung_opacity_folder):\n",
    "    if filename.endswith('.png'):\n",
    "        img = cv2.imread(os.path.join(lung_opacity_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        X.append(img)\n",
    "        y.append(1)  # Etiqueta 1 para Opacidad pulmonar\n",
    "\n",
    "# Cargar imágenes de pulmones sanos\n",
    "for filename in os.listdir(normal_folder):\n",
    "    if filename.endswith('.png'):\n",
    "        img = cv2.imread(os.path.join(normal_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        X.append(img)\n",
    "        y.append(2)  # Etiqueta 2 para pulmones sanos\n",
    "\n",
    "# Cargar imágenes de pulmones con neumonía viral\n",
    "for filename in os.listdir(viral_pneumonia_folder):\n",
    "    if filename.endswith('.png'):\n",
    "        img = cv2.imread(os.path.join(viral_pneumonia_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        X.append(img)\n",
    "        y.append(3)  # Etiqueta 3 para Neumonía viral\n",
    "\n",
    "# Convertir las listas en matrices numpy\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de imágenes por clase:\n",
      "\n",
      "COVID: 3616\n",
      "Opacidad pulmonar: 6012\n",
      "Pulmones sanos: 10192\n",
      "Neumonía viral: 1345\n",
      "Tamaño de X_entrenamiento: (16932, 89401)\n",
      "Tamaño de X_prueba: (4233, 89401)\n",
      "Tamaño de y_entrenamiento: (16932,)\n",
      "Tamaño de y_prueba: (4233,)\n"
     ]
    }
   ],
   "source": [
    "# Obtener la cantidad de imágenes en cada clase\n",
    "cantidad_covid = len(os.listdir(covid_folder))\n",
    "cantidad_opacidad_pulmonar = len(os.listdir(lung_opacity_folder))\n",
    "cantidad_pulmones_sanos = len(os.listdir(normal_folder))\n",
    "cantidad_neumonia_viral = len(os.listdir(viral_pneumonia_folder))\n",
    "\n",
    "# Imprimir la cantidad de imágenes en cada clase\n",
    "print(\"Cantidad de imágenes por clase:\\n\")\n",
    "print(\"COVID:\", cantidad_covid)\n",
    "print(\"Opacidad pulmonar:\", cantidad_opacidad_pulmonar)\n",
    "print(\"Pulmones sanos:\", cantidad_pulmones_sanos)\n",
    "print(\"Neumonía viral:\", cantidad_neumonia_viral)\n",
    "\n",
    "# Aplanar las imágenes en un vector unidimensional\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verificar el tamaño de las matrices\n",
    "print(\"Tamaño de X_entrenamiento:\", X_entrenamiento.shape)\n",
    "print(\"Tamaño de X_prueba:\", X_prueba.shape)\n",
    "print(\"Tamaño de y_entrenamiento:\", y_entrenamiento.shape)\n",
    "print(\"Tamaño de y_prueba:\", y_prueba.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preprocesamiento de las imágenes\n",
    "preprocessed_images = []\n",
    "for image in X:\n",
    "    # Redimensionar la imagen a un tamaño adecuado\n",
    "    resized_image = cv2.resize(image, (64, 64))  # Ajusta el tamaño según tus necesidades\n",
    "\n",
    "    # Normalizar la imagen\n",
    "    normalized_image = resized_image.astype(float) / 255.0  # Normalización en el rango [0, 1]\n",
    "\n",
    "    preprocessed_images.append(normalized_image)\n",
    "\n",
    "# Convertir las imágenes preprocesadas en una matriz numpy\n",
    "X_preprocessed = np.array(preprocessed_images)\n",
    "\n",
    "# Aplanar las imágenes preprocesadas en un vector unidimensional\n",
    "X_preprocessed = X_preprocessed.reshape(X_preprocessed.shape[0], -1)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar las características utilizando un escalador estándar\n",
    "scaler = StandardScaler()\n",
    "X_entrenamiento = scaler.fit_transform(X_entrenamiento)\n",
    "X_prueba = scaler.transform(X_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de X_entrenamiento: (16932, 4096)\n",
      "Tamaño de X_prueba: (4233, 4096)\n",
      "Tamaño de y_entrenamiento: (16932,)\n",
      "Tamaño de y_prueba: (4233,)\n"
     ]
    }
   ],
   "source": [
    "# Verificar el tamaño de las matrices\n",
    "print(\"Tamaño de X_entrenamiento:\", X_entrenamiento.shape)\n",
    "print(\"Tamaño de X_prueba:\", X_prueba.shape)\n",
    "print(\"Tamaño de y_entrenamiento:\", y_entrenamiento.shape)\n",
    "print(\"Tamaño de y_prueba:\", y_prueba.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones:  [2 2 2 ... 2 2 2]\n",
      "Valor real  :  [3 2 0 ... 1 1 0]\n",
      "Precisión: 0.48\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(activation='logistic', alpha=0.01, hidden_layer_sizes=(10,10), max_iter=1000, random_state=42, solver='sgd')\n",
    "\n",
    "start_time = time.time()\n",
    "mlp.fit(X_entrenamiento, y_entrenamiento)\n",
    "end_time = time.time()\n",
    "\n",
    "y_pred = mlp.predict(X_prueba)\n",
    "\n",
    "print(\"Predicciones: \", y_pred)\n",
    "print(\"Valor real  : \",y_prueba)\n",
    "\n",
    "accuracy = accuracy_score(y_prueba, y_pred)\n",
    "print(\"Precisión: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Metric       Score\n",
      "0         Recall    0.636822\n",
      "1      Precision    0.851878\n",
      "2       Accuracy    0.738176\n",
      "3             F1    0.664353\n",
      "4  Training Time  422.616639\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_pred, y_prueba, start_time, end_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba sin feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ruta de la carpeta que contiene las imágenes de pulmones con COVID\n",
    "covid_folder = 'dataset\\images\\COVID_target'\n",
    "# Ruta de la carpeta que contiene las imágenes de pulmones sanos\n",
    "healthy_folder = 'dataset\\images\\Other'\n",
    "\n",
    "# Lista para almacenar las imágenes y las etiquetas correspondientes\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Cargar imágenes de pulmones con COVID\n",
    "for filename in os.listdir(covid_folder):\n",
    "    if filename.endswith('.png'):\n",
    "        img = cv2.imread(os.path.join(covid_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        X.append(img)\n",
    "        y.append(1)  # Etiqueta 1 para COVID\n",
    "\n",
    "# Cargar imágenes de pulmones sanos\n",
    "for filename in os.listdir(healthy_folder):\n",
    "    if filename.endswith('.png'):\n",
    "        img = cv2.imread(os.path.join(healthy_folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        X.append(img)\n",
    "        y.append(0)  # Etiqueta 0 para pulmones sanos\n",
    "\n",
    "# Convertir las listas en matrices numpy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Aplanar las imágenes en un vector unidimensional\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de X_entrenamiento: (16932, 89401)\n",
      "Tamaño de X_prueba: (4233, 89401)\n",
      "Tamaño de y_entrenamiento: (16932,)\n",
      "Tamaño de y_prueba: (4233,)\n"
     ]
    }
   ],
   "source": [
    "# Verificar el tamaño de las matrices\n",
    "print(\"Tamaño de X_entrenamiento:\", X_entrenamiento.shape)\n",
    "print(\"Tamaño de X_prueba:\", X_prueba.shape)\n",
    "print(\"Tamaño de y_entrenamiento:\", y_entrenamiento.shape)\n",
    "print(\"Tamaño de y_prueba:\", y_prueba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_entrenamiento: [[158 157 151 ...   1   1   1]\n",
      " [ 55  70  75 ...   0   0   0]\n",
      " [  5   7   8 ...  48  52  55]\n",
      " [  2   3   3 ...  17  14  11]\n",
      " [237 237 238 ... 239 239 240]]\n",
      "X_prueba: [[203 201 198 ...  25  28  29]\n",
      " [ 49  59  66 ...   2  15  36]\n",
      " [  7  11  14 ...  26  32  45]\n",
      " [ 25  27  29 ... 215 216 216]\n",
      " [182 176 156 ...   0   0   0]]\n",
      "y_entrenamiento: [0 0 0 0 0]\n",
      "y_prueba: [0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Verificar el tamaño de las matrices\n",
    "print(\"X_entrenamiento:\", X_entrenamiento[0:5])\n",
    "print(\"X_prueba:\", X_prueba[0:5])\n",
    "print(\"y_entrenamiento:\", y_entrenamiento[0:5])\n",
    "print(\"y_prueba:\", y_prueba[0:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estandarización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Preprocesamiento de las imágenes\n",
    "# preprocessed_images = []\n",
    "# for image in X:\n",
    "#     # Normalizar la imagen\n",
    "#     normalized_image = resized_image.astype(float) / 255.0  # Normalización en el rango [0, 1]\n",
    "\n",
    "#     preprocessed_images.append(normalized_image)\n",
    "\n",
    "# # Convertir las imágenes preprocesadas en una matriz numpy\n",
    "# X_preprocessed = np.array(preprocessed_images)\n",
    "\n",
    "# # Aplanar las imágenes preprocesadas en un vector unidimensional\n",
    "# X_preprocessed = X_preprocessed.reshape(X_preprocessed.shape[0], -1)\n",
    "\n",
    "# # Dividir el conjunto de datos en entrenamiento y prueba\n",
    "# X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Normalizar las características utilizando un escalador estándar\n",
    "# scaler = StandardScaler()\n",
    "# X_entrenamiento = scaler.fit_transform(X_entrenamiento)\n",
    "# X_prueba = scaler.transform(X_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de X_entrenamiento: (16932, 89401)\n",
      "Tamaño de X_prueba: (4233, 89401)\n",
      "Tamaño de y_entrenamiento: (16932,)\n",
      "Tamaño de y_prueba: (4233,)\n"
     ]
    }
   ],
   "source": [
    "# Verificar el tamaño de las matrices\n",
    "print(\"Tamaño de X_entrenamiento:\", X_entrenamiento.shape)\n",
    "print(\"Tamaño de X_prueba:\", X_prueba.shape)\n",
    "print(\"Tamaño de y_entrenamiento:\", y_entrenamiento.shape)\n",
    "print(\"Tamaño de y_prueba:\", y_prueba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_entrenamiento: [[158 157 151 ...   1   1   1]\n",
      " [ 55  70  75 ...   0   0   0]\n",
      " [  5   7   8 ...  48  52  55]\n",
      " [  2   3   3 ...  17  14  11]\n",
      " [237 237 238 ... 239 239 240]]\n",
      "X_prueba: [[203 201 198 ...  25  28  29]\n",
      " [ 49  59  66 ...   2  15  36]\n",
      " [  7  11  14 ...  26  32  45]\n",
      " [ 25  27  29 ... 215 216 216]\n",
      " [182 176 156 ...   0   0   0]]\n",
      "y_entrenamiento: [0 0 0 0 0]\n",
      "y_prueba: [0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Verificar el tamaño de las matrices\n",
    "print(\"X_entrenamiento:\", X_entrenamiento[0:5])\n",
    "print(\"X_prueba:\", X_prueba[0:5])\n",
    "print(\"y_entrenamiento:\", y_entrenamiento[0:5])\n",
    "print(\"y_prueba:\", y_prueba[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones:  [0 0 0 ... 0 0 0]\n",
      "Valor real  :  [0 0 1 ... 0 0 1]\n",
      "Precisión: 0.83\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(activation='logistic', alpha=0.01, hidden_layer_sizes=(10,10), max_iter=1000, random_state=42, solver='sgd')\n",
    "\n",
    "start_time = time.time()\n",
    "mlp.fit(X_entrenamiento, y_entrenamiento)\n",
    "end_time = time.time()\n",
    "\n",
    "y_pred = mlp.predict(X_prueba)\n",
    "\n",
    "print(\"Predicciones: \", y_pred)\n",
    "print(\"Valor real  : \",y_prueba)\n",
    "\n",
    "accuracy = accuracy_score(y_prueba, y_pred)\n",
    "print(\"Precisión: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Metric       Score\n",
      "0         Recall    0.500000\n",
      "1      Precision    0.834396\n",
      "2       Accuracy    0.917198\n",
      "3             F1    0.454862\n",
      "4  Training Time  570.593125\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_pred, y_prueba, start_time, end_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
